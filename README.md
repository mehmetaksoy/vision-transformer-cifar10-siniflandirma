# Vision Transformer ile CIFAR-10 GÃ¶rÃ¼ntÃ¼ SÄ±nÄ±flandÄ±rma

Bu proje, **Vision Transformer (ViT)** mimarisini kullanarak CIFAR-10 veri seti Ã¼zerinde gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma gÃ¶revini gerÃ§ekleÅŸtirmektedir. TransformatÃ¶r mimarilerinin gÃ¶rÃ¼ntÃ¼ anlama gÃ¶revlerindeki etkinliÄŸini gÃ¶stermek amacÄ±yla geliÅŸtirilmiÅŸtir.

## ğŸ“Š Proje Ã–zeti

- **Model:** google/vit-base-patch16-224 (Ã¶nceden eÄŸitilmiÅŸ)
- **Veri Seti:** CIFAR-10 (50,000 eÄŸitim + 10,000 test gÃ¶rÃ¼ntÃ¼sÃ¼)
- **Test DoÄŸruluÄŸu:** %98.83
- **SÄ±nÄ±f SayÄ±sÄ±:** 10 kategori
- **EÄŸitim SÃ¼resi:** ~129 dakika (NVIDIA L4 GPU)

## ğŸ¯ SÄ±nÄ±flandÄ±rma Kategorileri

Proje aÅŸaÄŸÄ±daki 10 farklÄ± nesne kategorisini tanÄ±yabilir:

1. **UÃ§ak** (airplane)
2. **Otomobil** (automobile) 
3. **KuÅŸ** (bird)
4. **Kedi** (cat)
5. **Geyik** (deer)
6. **KÃ¶pek** (dog)
7. **KurbaÄŸa** (frog)
8. **At** (horse)
9. **Gemi** (ship)
10. **Kamyon** (truck)

## ğŸš€ Ã–zellikler

- **Vision Transformer (ViT) Mimarisi:** Geleneksel CNN'lere alternatif olarak patch tabanlÄ± gÃ¶rÃ¼ntÃ¼ iÅŸleme
- **Transfer Ã–ÄŸrenme:** ImageNet Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸ model kullanÄ±mÄ±
- **Veri ArtÄ±rma:** RandomResizedCrop ve RandomHorizontalFlip teknikleri
- **KapsamlÄ± DeÄŸerlendirme:** Accuracy, Precision, Recall, F1-Score, AUC metrikleri
- **GÃ¶rselleÅŸtirme:** KarmaÅŸÄ±klÄ±k matrisi ve ROC eÄŸrileri
- **Performans Analizi:** EÄŸitim sÃ¼releri ve Ã§Ä±karÄ±m hÄ±zÄ± analizi

## ğŸ“‹ Gereksinimler

```bash
# Temel kÃ¼tÃ¼phaneler
torch>=2.0.0
torchvision>=0.15.0
transformers==4.48.3
datasets==3.6.0

# Veri iÅŸleme ve gÃ¶rselleÅŸtirme
numpy>=1.20.0
pandas>=1.3.0
scikit-learn>=1.0.0
matplotlib>=3.3.0
seaborn>=0.11.0
Pillow>=8.0.0

# Notebook ortamÄ± iÃ§in
tqdm>=4.60.0
```

## ğŸ› ï¸ Kurulum

1. **Repository'yi klonlayÄ±n:**
```bash
git clone https://github.com/kullanici-adi/vision-transformer-cifar10-siniflandirma.git
cd vision-transformer-cifar10-siniflandirma
```

2. **Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:**
```bash
pip install -r requirements.txt
```

3. **Google Colab iÃ§in:** Notebook'u doÄŸrudan aÃ§Ä±p Ã§alÄ±ÅŸtÄ±rabilirsiniz.

## ğŸ“ Proje YapÄ±sÄ±

```
vision-transformer-cifar10-siniflandirma/
â”‚
â”œâ”€â”€ Vision_Transformer_(ViT)_ile_GÃ¶rÃ¼ntÃ¼_SÄ±nÄ±flandÄ±rma_(CIFAR_10)Kopya.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ proje_raporu.md
â””â”€â”€ results/
    â”œâ”€â”€ confusion_matrix.png
    â”œâ”€â”€ roc_curves.png
    â””â”€â”€ training_logs.png
```

## ğŸ”„ KullanÄ±m

### Notebook ile Ã‡alÄ±ÅŸtÄ±rma

1. **Google Colab'da aÃ§Ä±n** veya Jupyter Notebook kullanÄ±n
2. **GPU'yu etkinleÅŸtirin** (Runtime â†’ Change runtime type â†’ GPU)
3. **HÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n:**
   - HÃ¼cre 1: KÃ¼tÃ¼phane kurulumu
   - HÃ¼cre 2: Import ve versiyon kontrolÃ¼
   - HÃ¼cre 3: CIFAR-10 veri setini yÃ¼kleme
   - HÃ¼cre 4: Veri Ã¶n iÅŸleme ve augmentasyon
   - HÃ¼cre 5: ViT modelini yÃ¼kleme
   - HÃ¼cre 6: Model eÄŸitimi
   - HÃ¼cre 7-9: DeÄŸerlendirme ve gÃ¶rselleÅŸtirme

### Python Scripti ile Ã‡alÄ±ÅŸtÄ±rma

```python
from transformers import AutoImageProcessor, AutoModelForImageClassification
from datasets import load_dataset

# Veri setini yÃ¼kle
dataset = load_dataset("cifar10")

# Model ve iÅŸlemciyi yÃ¼kle
processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")
model = AutoModelForImageClassification.from_pretrained("google/vit-base-patch16-224", num_labels=10)

# EÄŸitim kodunuz buraya...
```

## ğŸ“ˆ Performans Metrikleri

### Test Seti SonuÃ§larÄ±

| Metrik | DeÄŸer |
|--------|--------|
| **DoÄŸruluk (Accuracy)** | %98.83 |
| **Precision (Macro)** | 0.9883 |
| **Recall (Macro)** | 0.9883 |
| **F1-Score (Macro)** | 0.9883 |
| **Specificity (Macro)** | 0.9987 |
| **AUC (Macro)** | 0.9996 |

### EÄŸitim DetaylarÄ±

- **Epoch SayÄ±sÄ±:** 10
- **Batch Size:** 32 (eÄŸitim), 64 (deÄŸerlendirme)
- **Ã–ÄŸrenme OranÄ±:** 2e-5
- **Warmup OranÄ±:** 0.1
- **Weight Decay:** 0.01
- **Toplam EÄŸitim SÃ¼resi:** 129.17 dakika
- **Ã‡Ä±karÄ±m HÄ±zÄ±:** 7,845 gÃ¶rÃ¼ntÃ¼/saniye

## ğŸ§  Model Mimarisi

**Vision Transformer (ViT)** Ã¶zellikleri:
- **Patch Boyutu:** 16x16 piksel
- **Girdi Ã‡Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼:** 224x224 piksel
- **Toplam Parametre:** ~85.8 milyon
- **Ã–nceden EÄŸitilmiÅŸ:** ImageNet dataset
- **Patch SayÄ±sÄ±:** 196 (14x14 grid)

## ğŸ“Š GÃ¶rselleÅŸtirmeler

Proje aÅŸaÄŸÄ±daki gÃ¶rselleÅŸtirmeleri iÃ§erir:

1. **Rastgele Ã–rnek GÃ¶rÃ¼ntÃ¼ler:** Veri setinden Ã¶rnek gÃ¶rÃ¼ntÃ¼ler ve etiketleri
2. **KarmaÅŸÄ±klÄ±k Matrisi:** SÄ±nÄ±flar arasÄ± tahmin performansÄ±
3. **ROC EÄŸrileri:** Ã‡ok sÄ±nÄ±flÄ± AUC analizi
4. **EÄŸitim Grafikleri:** Epoch bazÄ±nda kayÄ±p ve metrik deÄŸiÅŸimleri

## ğŸ”§ Teknik Detaylar

### Veri Ã–n Ä°ÅŸleme
- **GÃ¶rÃ¼ntÃ¼ BoyutlandÄ±rma:** 224x224 piksel
- **Normalizasyon:** ImageNet istatistikleri
- **Augmentasyon:** RandomResizedCrop, RandomHorizontalFlip
- **Format DÃ¶nÃ¼ÅŸÃ¼mÃ¼:** PIL â†’ PyTorch tensÃ¶r

### Model YapÄ±landÄ±rmasÄ±
- **Transfer Learning:** Ã–nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klar
- **Fine-tuning:** TÃ¼m katmanlar eÄŸitildi
- **SÄ±nÄ±flandÄ±rÄ±cÄ±:** 10 sÄ±nÄ±f iÃ§in yeni baÅŸlÄ±k
- **Optimizasyon:** AdamW optimizer

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/yeni-ozellik`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -am 'Yeni Ã¶zellik eklendi'`)
4. Branch'inizi push edin (`git push origin feature/yeni-ozellik`)
5. Pull Request oluÅŸturun

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

## ğŸ™ TeÅŸekkÃ¼rler

- **Hugging Face:** Transformers ve Datasets kÃ¼tÃ¼phaneleri
- **Google Research:** Vision Transformer modeli
- **CIFAR-10:** Benchmark veri seti
- **PyTorch:** Derin Ã¶ÄŸrenme framework'Ã¼


## ğŸ“ Ä°letiÅŸim

ğŸ› **Bug Report**: GitHub Issues kullanÄ±n  
ğŸ’¡ **Feature Request**: Discussions bÃ¶lÃ¼mÃ¼nden Ã¶nerinizi paylaÅŸÄ±n  
ğŸ“§ E-posta: [mehmetaksoy49@gmail.com]

- Pull Request ile katkÄ±da bulunun
- Projeyi yÄ±ldÄ±zlamayÄ± unutmayÄ±n! â­

---

**Not**: Bu proje eÄŸitim amaÃ§lÄ± geliÅŸtirilmiÅŸtir ve akademik Ã§alÄ±ÅŸmalarda referans olarak kullanÄ±labilir.
