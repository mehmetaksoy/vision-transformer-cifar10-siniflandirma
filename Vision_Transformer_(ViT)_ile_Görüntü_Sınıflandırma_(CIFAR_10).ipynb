{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 1: Gerekli Kütüphanelerin Kurulumu (ViT için)\n",
        "\n",
        "* **Amaç:**\n",
        "    Vision Transformer (ViT) modeli ile görüntü sınıflandırma görevi için gerekli olan Python kütüphanelerinin Google Colab ortamına kurulması ve/veya güncellenmesi. Bu adım, projenin sonraki aşamalarında ihtiyaç duyulacak araçların (Hugging Face Transformers, Datasets, PyTorch, Torchvision vb.) doğru ve uyumlu versiyonlarının hazır olmasını sağlar.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  **Temel Transformatör Kütüphaneleri:**\n",
        "        * `datasets`: Görüntü veri setlerini (örn: CIFAR-10) yüklemek ve işlemek için. Önceki projelerde stabil çalıştığını gördüğümüz `3.6.0` versiyonu hedeflenir.\n",
        "        * `transformers`: ViT modelini, görüntü işlemcisini (`image processor` / `feature extractor`) ve `Trainer` API'sini kullanmak için. Önceki projelerde stabil çalıştığını gördüğümüz `4.48.3` versiyonu hedeflenir.\n",
        "    2.  **Görüntü İşleme Kütüphaneleri:**\n",
        "        * `torchvision`: PyTorch tabanlı görüntü yükleme, ön işleme (transformasyonlar, augmentasyon) ve standart görüntü veri setlerine erişim için temel bir kütüphanedir. Genellikle PyTorch versiyonuyla uyumlu bir versiyonu kurulur veya Colab'da zaten mevcuttur.\n",
        "    3.  **Diğer Yardımcı Kütüphaneler:**\n",
        "        * `scikit-learn`: Performans metriklerini hesaplamak için.\n",
        "        * `matplotlib`, `seaborn`: Görselleştirmeler için.\n",
        "    4.  **Kurulum Stratejisi:**\n",
        "        * Önceki başarılı deneyimlerimize dayanarak, Colab'ın varsayılan temel kütüphanelerine (NumPy, Pandas vb.) doğrudan müdahale etmekten kaçınılır.\n",
        "        * `datasets` ve `transformers` için bilinen stabil versiyonlar (`3.6.0` ve `4.48.3`) hedeflenir.\n",
        "        * `torchvision`, genellikle Colab'da PyTorch ile birlikte geldiği ve uyumlu olduğu için ayrıca versiyon belirtilmeden kurulabilir/güncellenebilir (eğer gerekirse). Diğer kütüphaneler (`scikit-learn`, `matplotlib`, `seaborn`) için `pip`'in uyumlu güncel versiyonları seçmesine izin verilir.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar (Beklenen):**\n",
        "    * Bu hücre çalıştırıldığında, belirtilen kütüphaneler Colab ortamına kurulur/güncellenir.\n",
        "    * Kurulum sırasında `pip`'in bağımlılık çözümleyicisi uyarılar verebilir; bunlar not edilecektir.\n",
        "    * Hücre sonunda, kurulumların tamamlandığına dair bir mesaj ve **Colab çalışma zamanını \"Restart runtime\" ile yeniden başlatma** uyarısı verilecektir. Bu, yeni kurulan kütüphanelerin ortam tarafından doğru şekilde tanınması için zorunludur.\n",
        "    * Yeniden başlatma sonrası, bu Hücre 1 **tekrar çalıştırılmamalıdır.**"
      ],
      "metadata": {
        "id": "053GdyFvA2Yh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPLq3yDy_6-c"
      },
      "outputs": [],
      "source": [
        "# Hücre 1: Gerekli Kütüphanelerin Kurulumu (ViT için)\n",
        "\n",
        "# Lütfen bu hücreyi çalıştırmadan önce, eğer yeni bir not defteri değilse,\n",
        "# Colab çalışma zamanını \"Disconnect and delete runtime\" ile sıfırlamanız önerilir.\n",
        "# Eğer yeni bir not defteri ise doğrudan çalıştırabilirsiniz.\n",
        "\n",
        "print(\"ViT (Vision Transformer) projesi için gerekli kütüphaneler kuruluyor...\")\n",
        "\n",
        "# 1. Başarılı önceki projelerdeki stabil versiyonları hedefleyelim:\n",
        "#    NumPy ve Pandas'a dokunmuyoruz, Colab'ın varsayılanını kullanacağız.\n",
        "\n",
        "# Datasets ve Transformers için bilinen iyi versiyonlar:\n",
        "!pip install datasets==3.6.0 -q\n",
        "print(\"Datasets 3.6.0 kuruldu.\")\n",
        "\n",
        "!pip install transformers==4.48.3 -q\n",
        "print(\"Transformers 4.48.3 kuruldu.\")\n",
        "\n",
        "# 2. Görüntü işleme kütüphaneleri:\n",
        "# torchvision genellikle PyTorch ile uyumlu gelir ve Colab'da genellikle güncel bir versiyonu bulunur.\n",
        "# İhtiyaç halinde güncelleyebiliriz veya spesifik bir versiyon kurabiliriz. Şimdilik sadece kuralım.\n",
        "!pip install torchvision -q\n",
        "print(\"torchvision kuruldu/güncellendi.\")\n",
        "\n",
        "# 3. Diğer yardımcı kütüphaneler\n",
        "!pip install scikit-learn matplotlib seaborn Pillow -q\n",
        "# Pillow (PIL Fork) görüntü işleme için torchvision ve diğerleri tarafından kullanılır, güncel olmasında fayda var.\n",
        "print(\"Scikit-learn, Matplotlib, Seaborn ve Pillow kuruldu/güncellendi.\")\n",
        "\n",
        "print(\"\\nKütüphane kurulumları (Hücre 1) tamamlandı.\")\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "print(\"!!! LÜTFEN ŞİMDİ Colab Çalışma Zamanını (Runtime -> Restart runtime)      !!!\")\n",
        "print(\"!!! KESİNLİKLE YENİDEN BAŞLATIN. Bu, kurulumların oturmasını sağlar.         !!!\")\n",
        "print(\"!!! Yeniden başlattıktan sonra Hücre 1'i TEKRAR ÇALIŞTIRMAYIN,           !!!\")\n",
        "print(\"!!! doğrudan Hücre 2'ye (Kütüphane Importları) geçin.                   !!!\")\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 2: Kütüphanelerin Import Edilmesi, Versiyon Kontrolü ve Cihaz Belirleme (ViT için)\n",
        "\n",
        "* **Amaç:**\n",
        "    Çalışma zamanı yeniden başlatıldıktan sonra, Hücre 1'de kurulan ve Colab'da zaten mevcut olan temel kütüphaneleri Python çalışma ortamına dahil etmek. Görüntü sınıflandırma projesi için gerekli olan `torchvision` gibi kütüphanelerin de doğru import edildiğini teyit etmek. Kullanılan tüm ana kütüphanelerin versiyonlarını kontrol ederek tekrarlanabilirliği sağlamak ve projenin hangi sürümlerle geliştirildiğini belgelemek. Model eğitimi ve çıkarımı için kullanılacak donanım cihazını (CPU veya GPU) belirlemek.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  Gerekli tüm kütüphaneler (`transformers`, `datasets`, `torch`, `torchvision`, `numpy`, `pandas`, `sklearn`, `matplotlib`, `PIL` (Pillow), `sys`, `time`) `import` edilir.\n",
        "    2.  Hugging Face `datasets` ve `transformers` kütüphanelerinden ViT için sık kullanılacak sınıflar (örn: `load_dataset`, `AutoImageProcessor` veya `ViTImageProcessor`, `AutoModelForImageClassification` veya `ViTForImageClassification`, `TrainingArguments`, `Trainer`) ayrıca import edilir veya edileceği belirtilir.\n",
        "    3.  GPU varlığı `torch.cuda.is_available()` ile saptanır ve `device` değişkeni `cuda` veya `cpu` olarak ayarlanır.\n",
        "    4.  İsteğe bağlı olarak Python uyarıları bastırılır.\n",
        "    5.  Import edilen ana kütüphanelerin versiyonları ekrana yazdırılır. Özellikle `torch`, `torchvision`, `transformers`, `datasets` ve `numpy` versiyonları önemlidir.\n",
        "    6.  Kullanılacak cihaz ve eğer GPU aktifse ek CUDA/cuDNN bilgileri gösterilir.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar (Beklenen):**\n",
        "    * Bu hücrenin sorunsuz çalışması, Hücre 1'deki kurulumların ve ardından yapılan çalışma zamanı yeniden başlatmanın ortamı ViT projesi için doğru şekilde hazırladığını gösterir.\n",
        "    * Çıktıda listelenen kütüphane versiyonları, projenin bu bölümünün hangi ortamda geliştirildiğini belgeler. Önceki başarılı projelerimizden elde ettiğimiz `datasets==3.6.0`, `transformers==4.48.3` ve uyumlu bir NumPy versiyonu (Colab'ın o anki varsayılanı) burada da görülmesi ve tüm importların hatasız olması beklenir.\n",
        "    * \"KULLANILACAK CİHAZ\" satırında `cuda` (eğer Colab'da GPU aktifse) veya `cpu` yazar. Görüntü işleme modellerinin eğitimi genellikle GPU üzerinde çok daha verimlidir."
      ],
      "metadata": {
        "id": "H8CVVxb5BuUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 2: Kütüphanelerin Import Edilmesi, Versiyon Kontrolü ve Cihaz Belirleme (ViT için)\n",
        "\n",
        "# Temel ve Hugging Face kütüphanelerinin import edilmesi\n",
        "import transformers\n",
        "import datasets\n",
        "import torch\n",
        "import torchvision # Görüntü işleme ve veri setleri için PyTorch kütüphanesi\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn # scikit-learn'ün ana modülü\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt # matplotlib.pyplot'ı ayrıca import etmek iyi bir pratiktir\n",
        "import seaborn as sns\n",
        "from PIL import Image # Pillow kütüphanesi görüntü açma/işleme için\n",
        "import sys    # Python versiyonunu almak için\n",
        "import time   # Süre ölçümleri için\n",
        "\n",
        "# Hugging Face kütüphanelerinden sık kullanılacak modüller (ilerleyen aşamalarda)\n",
        "from datasets import load_dataset\n",
        "# ViT için genellikle AutoImageProcessor veya ViTImageProcessor kullanılır\n",
        "# from transformers import AutoImageProcessor, ViTImageProcessor\n",
        "# from transformers import AutoModelForImageClassification, ViTForImageClassification\n",
        "# from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Cihazı belirleme: GPU varsa GPU, yoksa CPU kullanılacak.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# İsteğe bağlı: Daha temiz bir çıktı için uyarıları bastırma\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"Kütüphaneler başarıyla import edildi.\")\n",
        "print(\"-\" * 50)\n",
        "print(\"KULLANILAN KÜTÜPHANE VERSİYONLARI:\")\n",
        "print(f\"  Python Versiyonu (sys.version): {sys.version.split()[0]}\")\n",
        "print(f\"  PyTorch: {torch.__version__}\")\n",
        "print(f\"  Torchvision: {torchvision.__version__}\")\n",
        "print(f\"  Transformers: {transformers.__version__}\")\n",
        "print(f\"  Datasets: {datasets.__version__}\")\n",
        "print(f\"  Numpy: {np.__version__}\")\n",
        "print(f\"  Pandas: {pd.__version__}\")\n",
        "print(f\"  Scikit-learn: {sklearn.__version__}\")\n",
        "print(f\"  Matplotlib: {matplotlib.__version__}\")\n",
        "print(f\"  Seaborn: {sns.__version__}\")\n",
        "print(f\"  Pillow (PIL): {Image.__version__}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"KULLANILACAK CİHAZ: {device}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(f\"  CUDA Versiyonu (torch.version.cuda): {torch.version.cuda}\")\n",
        "    print(f\"  cuDNN Versiyonu (torch.backends.cudnn.version()): {torch.backends.cudnn.version()}\")\n",
        "    print(f\"  Kullanılabilir GPU Sayısı: {torch.cuda.device_count()}\")\n",
        "    if torch.cuda.device_count() > 0:\n",
        "        print(f\"  Aktif GPU Adı: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"-\" * 50)\n",
        "else:\n",
        "    print(\"Uyarı: GPU bulunamadı veya aktif değil. Model eğitimi CPU üzerinde daha yavaş olacaktır.\")\n",
        "    print(\"Colab'da GPU'yu aktifleştirmek için 'Runtime' -> 'Change runtime type' menüsünü kullanabilirsiniz.\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "TQbbHVIVBwyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 3: Görüntü Veri Setinin Yüklenmesi (CIFAR-10) ve Temel İnceleme\n",
        "\n",
        "* **Amaç:**\n",
        "    Vision Transformer (ViT) ile görüntü sınıflandırma görevi için standart bir benchmark olan CIFAR-10 veri setini Hugging Face `datasets` kütüphanesiyle yüklemek. Veri setinin yapısını, içerdiği özellikleri (görüntü ve etiket), sınıf sayısını, etiket isimlerini anlamak ve örnek görüntüleri görselleştirerek veri hakkında fikir edinmek.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  `load_dataset(\"cifar10\")` fonksiyonu kullanılarak CIFAR-10 veri seti (`dataset_cifar_raw` olarak) Hugging Face Hub'dan yüklenir. Bu veri seti genellikle `train` ve `test` olmak üzere iki alt küme içerir.\n",
        "    2.  Yüklenen ham `DatasetDict` yapısı (alt kümeler, her bir alt kümedeki özellikler ve örnek sayıları) ekrana yazdırılır. Özellikle `img` (görüntü) ve `label` (sınıf etiketi) özellikleri incelenir.\n",
        "    3.  Eğitim setindeki `label` özelliğinden (`dataset_cifar_raw['train'].features['label']`) `ClassLabel` objesi alınır ve `label_feature_cifar` adlı bir değişkende saklanır. Bu obje, etiketlerin metin karşılıklarını (`names`) ve toplam sınıf sayısını (`num_classes`) içerir.\n",
        "    4.  Eğitim setinden rastgele birkaç örnek görüntü seçilir ve `matplotlib.pyplot` kullanılarak etiketleriyle birlikte görselleştirilir. Bu, veri setindeki görüntülerin nasıl göründüğü ve etiketlerin doğruluğu hakkında fikir verir.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar (Beklenen):**\n",
        "    * CIFAR-10 veri setinin Hugging Face Hub'dan sorunsuz bir şekilde indirilip yüklenmesi.\n",
        "    * `DatasetDict` yapısının `train` (genellikle 50,000 örnek) ve `test` (genellikle 10,000 örnek) alt kümelerini içerdiğinin görülmesi.\n",
        "    * `img` özelliğinin `PIL.Image.Image` formatında, `label` özelliğinin ise 10 sınıflı bir `ClassLabel` olduğu teyit edilir. Etiket isimleri (örn: \"airplane\", \"automobile\", \"bird\" vb.) listelenir.\n",
        "    * Rastgele seçilen CIFAR-10 görüntülerinin etiketleriyle birlikte doğru bir şekilde gösterilmesi.\n",
        "    * Bu hücre, `dataset_cifar_raw` ve `label_feature_cifar` gibi sonraki adımlarda kullanılacak temel değişkenleri tanımlayacaktır."
      ],
      "metadata": {
        "id": "vLpO3FD4CPNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 3: Görüntü Veri Setinin Yüklenmesi (CIFAR-10) ve Temel İnceleme\n",
        "\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt # Görselleştirme için\n",
        "import numpy as np # Rastgele seçim ve görüntü işleme için\n",
        "import random # Rastgele örnek seçmek için\n",
        "\n",
        "# CIFAR-10 veri setini yükleyelim\n",
        "dataset_name_cifar = \"cifar10\"\n",
        "\n",
        "print(f\"'{dataset_name_cifar}' veri seti yükleniyor...\")\n",
        "try:\n",
        "    # dataset_cifar_raw'ı global yapalım\n",
        "    global dataset_cifar_raw\n",
        "    dataset_cifar_raw = load_dataset(dataset_name_cifar)\n",
        "\n",
        "    print(f\"\\n'{dataset_name_cifar}' veri seti başarıyla yüklendi.\")\n",
        "    print(\"\\nYüklenen Ham Veri Seti Yapısı:\")\n",
        "    print(dataset_cifar_raw)\n",
        "\n",
        "    # Eğitim setinin özelliklerini inceleyelim\n",
        "    # Önce hangi split'lerin olduğunu kontrol edelim.\n",
        "    available_splits_cifar = list(dataset_cifar_raw.keys())\n",
        "    if not available_splits_cifar:\n",
        "        raise ValueError(\"CIFAR-10 veri setinde hiçbir alt küme (split) bulunamadı.\")\n",
        "\n",
        "    split_to_inspect_cifar = 'train' if 'train' in available_splits_cifar else available_splits_cifar[0]\n",
        "\n",
        "    print(f\"\\n'{split_to_inspect_cifar}' alt kümesinin özellikleri (features):\")\n",
        "    print(dataset_cifar_raw[split_to_inspect_cifar].features)\n",
        "\n",
        "    # Etiket bilgisini alalım (label_feature_cifar'ı global yapalım)\n",
        "    global label_feature_cifar\n",
        "    if 'label' in dataset_cifar_raw[split_to_inspect_cifar].features:\n",
        "        label_feature_cifar = dataset_cifar_raw[split_to_inspect_cifar].features['label']\n",
        "        print(f\"\\nEtiket Bilgisi ('label' özelliği):\")\n",
        "        print(label_feature_cifar)\n",
        "        if hasattr(label_feature_cifar, 'names'):\n",
        "            print(f\"Toplam etiket sayısı: {label_feature_cifar.num_classes}\")\n",
        "            print(f\"Etiket isimleri: {label_feature_cifar.names}\")\n",
        "        else:\n",
        "            print(\"Uyarı: 'label' özelliği bir ClassLabel değil gibi görünüyor veya 'names' attribute'u yok.\")\n",
        "    else:\n",
        "        print(\"Uyarı: Veri setinde 'label' özelliği bulunamadı.\")\n",
        "        label_feature_cifar = None\n",
        "\n",
        "    # Eğitim setinden rastgele birkaç örnek görselleştirelim\n",
        "    if split_to_inspect_cifar in dataset_cifar_raw and len(dataset_cifar_raw[split_to_inspect_cifar]) > 0 and \\\n",
        "       label_feature_cifar is not None and hasattr(label_feature_cifar, 'names'):\n",
        "\n",
        "        print(f\"\\n'{split_to_inspect_cifar}' setinden rastgele örnek görüntüler:\")\n",
        "\n",
        "        num_samples_to_show = 5\n",
        "        # Rastgele indeksler seçelim\n",
        "        random_indices = random.sample(range(len(dataset_cifar_raw[split_to_inspect_cifar])), num_samples_to_show)\n",
        "\n",
        "        plt.figure(figsize=(15, 3)) # Figür boyutunu ayarla\n",
        "        for i, idx in enumerate(random_indices):\n",
        "            sample = dataset_cifar_raw[split_to_inspect_cifar][idx]\n",
        "            image = sample[\"img\"] # Bu bir PIL Image objesi olmalı\n",
        "            label_id = sample[\"label\"]\n",
        "            label_name = label_feature_cifar.int2str(label_id)\n",
        "\n",
        "            plt.subplot(1, num_samples_to_show, i + 1)\n",
        "            plt.imshow(image)\n",
        "            plt.title(f\"Etiket: {label_name}\\n(ID: {label_id})\")\n",
        "            plt.axis(\"off\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"\\n'{split_to_inspect_cifar}' seti boş, bulunamadı veya etiket bilgisi eksik; örnekler gösterilemiyor.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nVeri seti yüklenirken veya işlenirken bir hata oluştu: {e}\")\n",
        "    import traceback\n",
        "    print(traceback.format_exc())\n",
        "    if 'dataset_cifar_raw' in globals(): del dataset_cifar_raw\n",
        "    if 'label_feature_cifar' in globals(): del label_feature_cifar"
      ],
      "metadata": {
        "id": "W6OypTU3CRTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 4: Görüntü Veri Seti İçin Veri Ön İşleme ve Augmentasyon (ViT için - `KeyError` Düzeltmesi)\n",
        "\n",
        "* **Amaç:**\n",
        "    CIFAR-10 veri setini Vision Transformer (ViT) modelinin eğitimi ve değerlendirmesi için hazırlamak. Bu, bir doğrulama seti oluşturmayı, uygun bir görüntü işlemcisi (image processor) kullanarak görüntüleri ViT'nin beklediği formata (boyut, normalizasyon) getirmeyi ve eğitim setine veri augmentasyonu uygulayarak modelin genelleme yeteneğini artırmayı içerir. Bir önceki denemede `image_processor.size[\"shortest_edge\"]` erişiminde `KeyError` alınmıştı, bu düzeltilecektir. `image_processor.size` genellikle `{'height': Y, 'width': X}` şeklinde bir sözlüktür.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  **Doğrulama Seti Oluşturma:** `dataset_cifar_raw['train']` alt kümesi, %90 eğitim ve %10 doğrulama olarak bölünür.\n",
        "    2.  **Image Processor Yükleme:** ViT modeli (`\"google/vit-base-patch16-224\"`) için `AutoImageProcessor` yüklenir.\n",
        "    3.  **Veri Dönüşümleri (Transforms) Tanımlama:**\n",
        "        * `image_processor`'ın kendisi, görüntüleri PIL formatından alıp gerekli tüm temel dönüşümleri (yeniden boyutlandırma, normalizasyon, tensöre çevirme) yapar.\n",
        "        * **Eğitim Seti İçin (`preprocess_train`):** Önce `torchvision.transforms` ile augmentasyonlar (örn: `RandomResizedCrop`, `RandomHorizontalFlip`) PIL görüntülerine uygulanır, ardından bu augmentasyon görmüş görüntüler `image_processor`'a verilerek tensörlere dönüştürülür.\n",
        "        * **Değerlendirme/Test Setleri İçin (`preprocess_eval`):** Görüntüler doğrudan `image_processor`'a verilerek gerekli boyutlandırma, normalizasyon ve tensör dönüşümü yapılır (augmentasyon uygulanmaz).\n",
        "            * **Düzeltme:** `Resize` ve `CenterCrop` için `image_processor.size` sözlüğündeki `height` ve `width` anahtarları doğru kullanılacaktır. ViT genellikle kare girdiler beklediği için, `image_processor.size['height']` (veya `image_processor.size['width']`) genellikle tek bir değere (örn: 224) karşılık gelir. `Resize` için bu tek değer veya `(değer, değer)` tupl'ı kullanılır.\n",
        "    4.  **Dönüşümleri Veri Setine Uygulama:** Tanımlanan `preprocess_train` ve `preprocess_eval` fonksiyonları, `processed_dataset_cifar`'ın ilgili alt kümelerine `.set_transform()` metodu ile atanır.\n",
        "    5.  Dönüştürülmüş bir örnek kontrol edilir.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar (Beklenen):**\n",
        "    * Veri setleri ve image processor başarıyla yüklenir.\n",
        "    * `KeyError: 'shortest_edge'` hatasının düzeltilmesiyle, değerlendirme seti için dönüşümler doğru tanımlanır. `image_processor.size` genellikle `{\"height\": 224, \"width\": 224}` gibi değerler içerir. `Resize` ve `CenterCrop` için bu değerler kullanılacaktır.\n",
        "    * `.set_transform()` ile atanan dönüşümler sayesinde, `DataLoader`'dan gelen her bir batch'teki görüntülerin modele uygun boyutta, normalize edilmiş ve PyTorch tensörleri formatında olması sağlanır.\n",
        "    * Dönüştürülmüş bir örneğin `pixel_values` (genellikle `(3, Yükseklik, Genişlik)` örn: `(3, 224, 224)`) ve `labels` anahtarlarını içerdiği görülür."
      ],
      "metadata": {
        "id": "ih8hlJD-C66J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 4: Görüntü Veri Seti İçin Veri Ön İşleme ve Augmentasyon (ViT için - KeyError Düzeltmesiyle)\n",
        "\n",
        "from transformers import AutoImageProcessor\n",
        "from torchvision.transforms import ( # Bu importlar, eğer manuel augmentasyon yapacaksak gerekli\n",
        "    Compose, RandomResizedCrop, RandomHorizontalFlip, ToTensor, Normalize,\n",
        "    Resize, CenterCrop\n",
        ")\n",
        "# datasets, torch, np, plt zaten Hücre 2'de import edilmişti.\n",
        "# dataset_cifar_raw ve label_feature_cifar Hücre 3'ten gelmeli.\n",
        "\n",
        "vit_checkpoint = \"google/vit-base-patch16-224\"\n",
        "\n",
        "if 'dataset_cifar_raw' in globals() and dataset_cifar_raw is not None and \\\n",
        "   'label_feature_cifar' in globals() and label_feature_cifar is not None:\n",
        "    print(\"CIFAR-10 veri seti ön işleme adımları başlatılıyor...\")\n",
        "\n",
        "    # 1. Doğrulama Seti Oluşturma\n",
        "    if 'train' in dataset_cifar_raw and 'test' in dataset_cifar_raw:\n",
        "        train_val_split = dataset_cifar_raw['train'].train_test_split(test_size=0.1, seed=42, stratify_by_column=\"label\")\n",
        "\n",
        "        global processed_dataset_cifar\n",
        "        processed_dataset_cifar = datasets.DatasetDict({\n",
        "            'train': train_val_split['train'],\n",
        "            'validation': train_val_split['test'],\n",
        "            'test': dataset_cifar_raw['test']\n",
        "        })\n",
        "        print(\"\\nEğitim seti, doğrulama ve test alt kümelerine ayrıldı:\")\n",
        "        print(processed_dataset_cifar)\n",
        "        print(f\"  Yeni Eğitim seti örnek sayısı: {len(processed_dataset_cifar['train'])}\")\n",
        "        print(f\"  Doğrulama seti örnek sayısı: {len(processed_dataset_cifar['validation'])}\")\n",
        "    else:\n",
        "        print(\"Hata: Ham CIFAR-10 veri setinde 'train' veya 'test' alt kümesi bulunamadı.\")\n",
        "        processed_dataset_cifar = None\n",
        "\n",
        "    if processed_dataset_cifar is not None:\n",
        "        # 2. Image Processor Yükleme\n",
        "        try:\n",
        "            global image_processor\n",
        "            image_processor = AutoImageProcessor.from_pretrained(vit_checkpoint)\n",
        "            print(f\"\\n'{vit_checkpoint}' için Image Processor başarıyla yüklendi.\")\n",
        "            # image_processor.size genellikle {'height': 224, 'width': 224} gibi bir sözlüktür.\n",
        "            # Veya bazen sadece image_processor.size integer olabilir (örn: 224).\n",
        "            # ViT modelleri genellikle kare girdiler bekler (örn: 224x224).\n",
        "            # `size` attribute'unun yapısını kontrol edelim.\n",
        "            # Genellikle image_processor.size bir int (örn: 224) veya {'shortest_edge': 224}\n",
        "            # veya {'height': 224, 'width': 224} döndürür.\n",
        "            # ViTImageProcessor için .size genellikle bir int'dir.\n",
        "            # AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\").size -> 224\n",
        "            # Dolayısıyla, image_processor.size[\"height\"] veya image_processor.size[\"shortest_edge\"] yerine\n",
        "            # doğrudan image_processor.size (eğer int ise) veya image_processor.size['height'] (eğer dict ise) kullanmalıyız.\n",
        "            # ViTFeatureExtractor (eski adı) için size bir int idi.\n",
        "            # ViTImageProcessor için, size attribute'u içinde 'height', 'width' veya 'shortest_edge' olabilir,\n",
        "            # ya da doğrudan bir int olabilir.\n",
        "            # En güvenlisi, processor'ın döndürdüğü config'e bakmak veya doğrudan size'ı kullanmak.\n",
        "            # `google/vit-base-patch16-224` için image_processor.size = {'height': 224, 'width': 224}\n",
        "            # Ancak hata `shortest_edge` için geldi. Bu, benim önceki kodumdaki bir varsayımdı.\n",
        "            # Doğrusu, ViT için genellikle kare bir çözünürlük vardır.\n",
        "\n",
        "            # image_processor.size'ın yapısını kontrol edelim:\n",
        "            # print(f\"Image processor size bilgisi: {image_processor.size}\")\n",
        "            # Çıktı genellikle şöyledir: {'height': 224, 'width': 224}\n",
        "            # veya bazen sadece int: 224\n",
        "            # ViT için genellikle kare olduğu için tek bir boyut (örn: 224) yeterlidir.\n",
        "            # Eğer image_processor.size bir sözlükse:\n",
        "            if isinstance(image_processor.size, dict):\n",
        "                target_size = (image_processor.size['height'], image_processor.size['width'])\n",
        "                crop_size = image_processor.size['height'] # Kare olduğu varsayımıyla\n",
        "            else: # Eğer int ise\n",
        "                target_size = (image_processor.size, image_processor.size)\n",
        "                crop_size = image_processor.size\n",
        "\n",
        "            print(f\"  Hedef görüntü boyutu: {target_size}\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Image processor yüklenirken veya size bilgisi alınırken hata: {e}\")\n",
        "            image_processor = None\n",
        "\n",
        "        if image_processor is not None:\n",
        "            # 3. Veri Dönüşümleri (Transforms) Tanımlama\n",
        "\n",
        "            # Eğitim seti için dönüşüm fonksiyonu\n",
        "            def preprocess_train(example_batch):\n",
        "                # example_batch['img'] bir PIL Image listesi olmalı\n",
        "                # ViT image_processor genellikle PIL görüntülerini veya NumPy dizilerini girdi olarak alır\n",
        "                # ve normalizasyon ile tensör dönüşümünü kendi içinde yapar.\n",
        "                # Augmentasyonları image_processor'DAN ÖNCE uygulamalıyız.\n",
        "\n",
        "                # Torchvision augmentasyonları\n",
        "                augmentations = Compose([\n",
        "                    RandomResizedCrop(size=target_size, scale=(0.8, 1.0)), # Boyut ve ölçek aralığı ayarlanabilir\n",
        "                    RandomHorizontalFlip(),\n",
        "                ])\n",
        "\n",
        "                # Augmentasyonları uygula\n",
        "                # example_batch['img'] bir liste ise, her birine uygulamalıyız\n",
        "                try:\n",
        "                    augmented_images = [augmentations(img.convert(\"RGB\")) for img in example_batch['img']]\n",
        "                except TypeError: # Eğer tek bir görüntü geliyorsa (batched=False ile map yapılırsa)\n",
        "                    augmented_images = augmentations(example_batch['img'].convert(\"RGB\"))\n",
        "\n",
        "\n",
        "                # Image processor'ı uygula\n",
        "                inputs = image_processor(images=augmented_images, return_tensors=\"pt\")\n",
        "                inputs['labels'] = example_batch['label']\n",
        "                return inputs\n",
        "\n",
        "            # Değerlendirme seti için dönüşüm fonksiyonu\n",
        "            def preprocess_eval(example_batch):\n",
        "                # Değerlendirme için sadece boyutlandırma ve normalizasyon (image_processor yapar)\n",
        "                # Görüntülerin RGB olduğundan emin olalım\n",
        "                try:\n",
        "                    rgb_images = [img.convert(\"RGB\") for img in example_batch['img']]\n",
        "                except TypeError:\n",
        "                    rgb_images = example_batch['img'].convert(\"RGB\")\n",
        "\n",
        "                inputs = image_processor(images=rgb_images, return_tensors=\"pt\")\n",
        "                inputs['labels'] = example_batch['label']\n",
        "                return inputs\n",
        "\n",
        "            print(\"\\nVeri setlerine dönüşümler atanıyor...\")\n",
        "            try:\n",
        "                # processed_dataset_cifar['train'].set_transform(preprocess_train, output_all_columns=False) # Hatalı kullanım\n",
        "                # Doğru kullanım:\n",
        "                processed_dataset_cifar['train'] = processed_dataset_cifar['train'].with_transform(preprocess_train)\n",
        "                processed_dataset_cifar['validation'] = processed_dataset_cifar['validation'].with_transform(preprocess_eval)\n",
        "                processed_dataset_cifar['test'] = processed_dataset_cifar['test'].with_transform(preprocess_eval)\n",
        "\n",
        "                print(\"Dönüşümler başarıyla atandı.\")\n",
        "\n",
        "                print(\"\\nDönüşümler atandı. Eğitim setinden bir örnek (dönüşüm sonrası) alınıyor:\")\n",
        "                sample_transformed = processed_dataset_cifar[\"train\"][0]\n",
        "                print(f\"  Dönüştürülmüş örnek anahtarları: {list(sample_transformed.keys())}\")\n",
        "                if 'pixel_values' in sample_transformed:\n",
        "                    print(f\"  pixel_values şekli: {sample_transformed['pixel_values'].shape}\")\n",
        "                if 'labels' in sample_transformed:\n",
        "                    print(f\"  labels değeri: {sample_transformed['labels']}\")\n",
        "            except Exception as e_set_transform:\n",
        "                print(f\"Dönüşümler atanırken veya örnek alınırken hata: {e_set_transform}\")\n",
        "                import traceback\n",
        "                print(traceback.format_exc())\n",
        "\n",
        "\n",
        "            print(\"\\nVeri ön işleme ve augmentasyon (Hücre 4) tamamlandı.\")\n",
        "        else:\n",
        "            print(\"Image processor yüklenemediği için veri dönüşümleri tanımlanamadı.\")\n",
        "else:\n",
        "    print(\"Hata: CIFAR-10 veri seti ('dataset_cifar_raw') veya etiket bilgisi ('label_feature_cifar') bulunamadı.\")"
      ],
      "metadata": {
        "id": "Nt5sMKa-C8IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 5: Vision Transformer (ViT) Modelinin Yüklenmesi\n",
        "\n",
        "* **Amaç:**\n",
        "    Görüntü sınıflandırma görevimiz (CIFAR-10) için önceden eğitilmiş bir Vision Transformer (ViT) modelini yüklemek ve veri setimizdeki sınıf sayısına (10 sınıf) uygun bir sınıflandırma başlığı (classification head) ile yapılandırmak.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  Hugging Face `transformers` kütüphanesinden `AutoModelForImageClassification` sınıfı kullanılacaktır. Bu sınıf, belirtilen bir checkpoint'ten önceden eğitilmiş bir görüntü modelini yükler ve üzerine bir görüntü sınıflandırma başlığı ekler.\n",
        "    2.  `vit_checkpoint` olarak Hücre 4'te image processor için kullandığımız `\"google/vit-base-patch16-224\"` (veya benzeri, ImageNet üzerinde önceden eğitilmiş bir ViT modeli) kullanılacaktır.\n",
        "    3.  `num_labels` parametresi, modelin sınıflandırma başlığının kaç çıktı nöronuna sahip olacağını belirtir. Bu değer, Hücre 3'te `label_feature_cifar.num_classes` ile elde ettiğimiz CIFAR-10 veri setindeki toplam sınıf sayısına (10) eşit olacaktır.\n",
        "    4.  **`ignore_mismatched_sizes=True`** parametresi, `from_pretrained` metoduna eklenecektir. Önceden eğitilmiş ViT modeli (örn: ImageNet üzerinde 1000 sınıf veya 21k sınıf için eğitilmiş) yüklenirken, bizim görevimiz için (CIFAR-10'da 10 sınıf) farklı sayıda etikete sahip bir sınıflandırma başlığına ihtiyaç duyulacaktır. `ignore_mismatched_sizes=True`, Hugging Face'in orijinal sınıflandırma başlığını atıp, `num_labels` ile belirttiğimiz sayıda sınıfa uygun, rastgele başlatılmış yeni bir sınıflandırma başlığı eklemesini sağlar. Bu, ince ayar (fine-tuning) için doğru yaklaşımdır.\n",
        "    5.  Yüklenen model, `model_vit.to(device)` komutu ile Hücre 2'de belirlenen cihaza (GPU: `cuda` veya CPU) taşınır.\n",
        "    6.  Modelin başarıyla yüklendiği, doğru cihaza taşındığı, toplam ve eğitilebilir parametre sayısı ve sınıflandırıcısının doğru sayıda etiket için (10) yapılandırıldığı teyit edilir.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar (Beklenen):**\n",
        "    * `\"google/vit-base-patch16-224\"` modelinin ağırlıkları Hugging Face Hub'dan indirilir.\n",
        "    * Çıktıda, sınıflandırma katmanının ağırlıklarının rastgele başlatıldığına ve modelin bu görev için eğitilmesi (fine-tuning) gerektiğine dair bir uyarı (`Some weights ... were not initialized...` veya `... newly initialized ...`) görülür. Bu, yeni bir görev için modelin üzerine yeni bir başlık eklendiğinde beklenen bir durumdur.\n",
        "    * Modelin GPU'ya başarıyla taşındığı belirtilir.\n",
        "    * Modeldeki toplam parametre sayısı (ViT-Base için ~86 milyon) ve bu parametrelerin büyük bir kısmının eğitilebilir olduğu gösterilir.\n",
        "    * Modelin yapılandırmasındaki (`model_vit.config.num_labels`) ve sınıflandırıcı katmanındaki etiket sayısının, veri setimizdeki sınıf sayısıyla (10) eşleştiği doğrulanır.\n",
        "    * `model_vit` adlı değişken, eğitilmek üzere hazır hale gelir."
      ],
      "metadata": {
        "id": "_iCsT2ucDxJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 5: Vision Transformer (ViT) Modelinin Yüklenmesi\n",
        "\n",
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "# vit_checkpoint Hücre 4'te tanımlanmıştı: \"google/vit-base-patch16-224\"\n",
        "# label_feature_cifar Hücre 3'te tanımlanmıştı ve sınıf sayısını içeriyordu.\n",
        "# device Hücre 2'de tanımlanmıştı.\n",
        "\n",
        "if 'vit_checkpoint' in globals() and \\\n",
        "   'label_feature_cifar' in globals() and label_feature_cifar is not None and hasattr(label_feature_cifar, 'num_classes') and \\\n",
        "   'device' in globals():\n",
        "\n",
        "    num_classes_cifar = label_feature_cifar.num_classes\n",
        "    print(f\"'{vit_checkpoint}' modeli '{num_classes_cifar}' etiket ile görüntü sınıflandırma görevi için yükleniyor...\")\n",
        "\n",
        "    try:\n",
        "        # model_vit'i global yapalım\n",
        "        global model_vit\n",
        "        model_vit = AutoModelForImageClassification.from_pretrained(\n",
        "            vit_checkpoint,\n",
        "            num_labels=num_classes_cifar,\n",
        "            ignore_mismatched_sizes=True, # Önceden eğitilmiş başlığın boyutunu önemseme, bizim num_labels'a göre yeni başlık oluştur.\n",
        "        )\n",
        "\n",
        "        model_vit.to(device) # Modeli tanımlanan cihaza (GPU/CPU) taşı\n",
        "\n",
        "        print(f\"\\nModel başarıyla yüklendi ve '{device}' cihazına taşındı.\")\n",
        "\n",
        "        total_params = sum(p.numel() for p in model_vit.parameters())\n",
        "        trainable_params = sum(p.numel() for p in model_vit.parameters() if p.requires_grad)\n",
        "        print(f\"\\nModeldeki toplam parametre sayısı: {total_params:,}\")\n",
        "        print(f\"Modeldeki eğitilebilir parametre sayısı: {trainable_params:,}\")\n",
        "\n",
        "        # Modelin ve sınıflandırıcısının doğru sayıda etiket için yapılandırıldığını doğrula\n",
        "        if hasattr(model_vit.config, 'num_labels'):\n",
        "            print(f\"Modelin yapılandırmasındaki etiket sayısı: {model_vit.config.num_labels}\")\n",
        "\n",
        "        # ViTForImageClassification'da sınıflandırıcı katmanı genellikle 'classifier' adındadır\n",
        "        # ve bir nn.Linear katmanıdır.\n",
        "        if hasattr(model_vit, 'classifier') and isinstance(model_vit.classifier, torch.nn.Linear):\n",
        "             print(f\"Sınıflandırıcı katmanının ('classifier') çıktı boyutu: {model_vit.classifier.out_features}\")\n",
        "        else:\n",
        "            # Farklı bir ViT varyantı veya özel bir başlık olabilir, son katmanı bulmaya çalışalım\n",
        "            final_layer = None\n",
        "            for _, module in reversed(list(model_vit.named_modules())):\n",
        "                if isinstance(module, torch.nn.Linear):\n",
        "                    final_layer = module\n",
        "                    break\n",
        "            if final_layer is not None:\n",
        "                print(f\"Modelin son Linear katmanının çıktı boyutu: {final_layer.out_features}\")\n",
        "                if final_layer.out_features != num_classes_cifar:\n",
        "                    print(f\"UYARI: Son linear katman çıktı boyutu ({final_layer.out_features}) num_labels ({num_classes_cifar}) ile eşleşmiyor!\")\n",
        "            else:\n",
        "                print(\"Sınıflandırıcı katmanının çıktı boyutu otomatik olarak tespit edilemedi, ancak num_labels doğru ayarlanmış olmalı.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nViT Modeli yüklenirken bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        if 'model_vit' in globals(): del model_vit\n",
        "else:\n",
        "    print(\"Hata: Gerekli değişkenler ('vit_checkpoint', 'label_feature_cifar', 'device') bulunamadı.\")\n",
        "    if 'model_vit' in globals(): del model_vit"
      ],
      "metadata": {
        "id": "uOb0_hhBDyaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 6: Eğitim Argümanları, Metrikler ve ViT Modelinin Eğitilmesi\n",
        "\n",
        "* **Amaç:**\n",
        "    Önceden eğitilmiş Vision Transformer (ViT) modelini, hazırladığımız CIFAR-10 veri seti üzerinde ince ayar (fine-tuning) yaparak görüntü sınıflandırma görevi için eğitmek. Eğitim sürecini kontrol edecek hiperparametreleri ayarlamak, her epoch sonunda model performansını izlemek için metrikleri hesaplamak ve en iyi modeli kaydetmek.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  **Performans Metriklerini Hesaplama Fonksiyonu (`compute_metrics_image_clf`):**\n",
        "        * `Trainer` tarafından her değerlendirme adımında çağrılacak bir fonksiyon tanımlanır.\n",
        "        * Girdi olarak modelin tahminlerini (`pred.predictions` - logitler) ve gerçek etiketleri (`pred.label_ids`) alır.\n",
        "        * `sklearn.metrics` kullanılarak proje isterlerinde belirtilen sınıflandırma metrikleri hesaplanır:\n",
        "            * **Accuracy:** Genel doğruluk.\n",
        "            * **Precision, Recall, F1-Score:** Bu metrikler çok sınıflı (10 sınıf) görevimiz için `average='macro'` (her sınıfın metriğini hesaplayıp ağırlıksız ortalamasını alır) veya `average='weighted'` (sınıf büyüklüğüne göre ağırlar) parametresiyle hesaplanır. `'macro'` F1 genellikle dengesiz olmayan veya tüm sınıfların eşit önemli olduğu durumlarda tercih edilir.\n",
        "            * **Specificity:** Çok sınıflı durumda her sınıf için ayrı ayrı (one-vs-rest mantığıyla) TN/(TN+FP) hesaplanıp ortalaması alınabilir.\n",
        "            * **AUC:** Çok sınıflı durumda ROC AUC, genellikle her sınıf için One-vs-Rest (OvR) stratejisiyle hesaplanır ve ortalaması alınır (`roc_auc_score(..., multi_class='ovr', average='macro')`).\n",
        "        * Hesaplanan metrikler bir sözlük olarak döndürülür.\n",
        "    2.  **`TrainingArguments` Tanımlanması:**\n",
        "        * Model eğitimi için ayarlar belirlenir:\n",
        "            * `output_dir`: Sonuçların kaydedileceği dizin (örn: `\"./vit_cifar10_results\"`).\n",
        "            * `num_train_epochs`: Epoch sayısı (görüntü modelleri için 5-10 veya daha fazla denenebilir).\n",
        "            * `per_device_train_batch_size` / `per_device_eval_batch_size`: Batch boyutları (GPU belleğine göre ayarlanır; ViT modelleri ve görüntü verileri için dikkatli seçilmelidir, örn: 32/64 veya 16/32).\n",
        "            * `evaluation_strategy=\"epoch\"`: Her epoch sonunda doğrulama seti üzerinde değerlendirme yapılır.\n",
        "            * `save_strategy=\"epoch\"`: Her epoch sonunda model checkpoint'i kaydedilir.\n",
        "            * `load_best_model_at_end=True` ve `metric_for_best_model`: Eğitim sonunda en iyi modeli (örn: \"eval\\_accuracy\" veya \"eval\\_f1_macro\") yükler.\n",
        "            * Diğer parametreler: `logging_strategy`, `learning_rate`, `weight_decay`, `warmup_steps`, `save_total_limit`.\n",
        "    3.  **Veri Harmanlama Fonksiyonu (`collate_fn`):**\n",
        "        * `Trainer` API'si, görüntü verilerini ve etiketlerini batch'ler halinde doğru bir şekilde birleştirmek için bir `collate_fn`'e ihtiyaç duyar. Hugging Face `transformers` genellikle `default_data_collator` sağlar. Eğer `image_processor` ile `.set_transform` kullanarak verileri zaten PyTorch tensörlerine (`pixel_values`, `labels`) dönüştürdüysek, `default_data_collator` genellikle yeterli olacaktır.\n",
        "    4.  **`Trainer` Objesinin Oluşturulması:**\n",
        "        * Parametreleri: `model_vit` (Hücre 5'te yüklenen), `args` (`TrainingArguments`), `processed_dataset_cifar[\"train\"]`, `processed_dataset_cifar[\"validation\"]`, `image_processor` (tokenizer olarak), `compute_metrics_image_clf` fonksiyonu ve `data_collator`.\n",
        "    5.  **Modelin Eğitilmesi:**\n",
        "        * `trainer_vit.train()` metodu ile model eğitimi başlatılır.\n",
        "        * Eğitim süresi ölçülür ve eğitim sonunda genel metrikler ile en iyi modelin kaydedildiği yol yazdırılır.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar (Beklenen):**\n",
        "    * `TrainingArguments` tanımlanır ve `Trainer` objesi başarıyla oluşturulur.\n",
        "    * Eğitim başlar. Her epoch sonunda eğitim kaybı, doğrulama kaybı ve `compute_metrics_image_clf` ile hesaplanan diğer doğrulama metrikleri loglanır.\n",
        "    * Eğitim tamamlandığında, en iyi performansı veren model `trainer_vit.model` içinde yüklü olur ve belirtilen yola kaydedilir.\n",
        "    * Bu hücre, ViT modelinin CIFAR-10 görüntü sınıflandırma görevinde ne kadar başarılı olduğunu ve öğrenme sürecini anlamamızı sağlar."
      ],
      "metadata": {
        "id": "8pnISgJ3ETdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 6: Eğitim Argümanları, Metrikler ve ViT Modelinin Eğitilmesi (Düzeltilmiş `remove_unused_columns` ile)\n",
        "\n",
        "from transformers import TrainingArguments, Trainer, default_data_collator\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
        "# numpy, torch, time, label_feature_cifar, model_vit, processed_dataset_cifar, image_processor, device\n",
        "# gibi değişkenlerin önceki hücrelerde doğru şekilde tanımlandığını varsayıyoruz.\n",
        "\n",
        "# 1. Performans Metriklerini Hesaplama Fonksiyonu (Görüntü Sınıflandırması İçin - öncekiyle aynı)\n",
        "def compute_metrics_image_clf(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    current_num_classes = label_feature_cifar.num_classes if 'label_feature_cifar' in globals() and label_feature_cifar else 10\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    try:\n",
        "        cm = confusion_matrix(labels, preds, labels=list(range(current_num_classes)))\n",
        "        tn, fp, fn, tp = 0,0,0,0 # Bu hesaplama çok sınıflı için daha karmaşık, specificity için farklı bir yol izleyelim\n",
        "        per_class_specificity_list = []\n",
        "        for i in range(current_num_classes):\n",
        "            temp_tn = np.sum(cm) - (np.sum(cm[i,:]) + np.sum(cm[:,i]) - cm[i,i])\n",
        "            temp_fp = np.sum(cm[:,i]) - cm[i,i]\n",
        "            if (temp_tn + temp_fp) > 0:\n",
        "                per_class_specificity_list.append(temp_tn / (temp_tn + temp_fp))\n",
        "            else:\n",
        "                per_class_specificity_list.append(0.0)\n",
        "        specificity_macro = np.mean(per_class_specificity_list) if per_class_specificity_list else 0.0\n",
        "    except ValueError:\n",
        "        specificity_macro = 0.0\n",
        "    auc_macro = 0.0\n",
        "    if pred.predictions.ndim == 2 and pred.predictions.shape[1] == current_num_classes:\n",
        "        try:\n",
        "            logits_tensor = torch.tensor(pred.predictions)\n",
        "            probs = torch.softmax(logits_tensor, dim=-1).cpu().numpy()\n",
        "            auc_macro = roc_auc_score(labels, probs, multi_class='ovr', average='macro', labels=list(range(current_num_classes)))\n",
        "        except ValueError: auc_macro = 0.0\n",
        "    return {\n",
        "        'accuracy': acc, 'precision_macro': precision_macro, 'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro, 'specificity_macro': specificity_macro, 'auc_macro': auc_macro\n",
        "    }\n",
        "\n",
        "# 2. Eğitim Argümanları (TrainingArguments) - DÜZELTİLMİŞ\n",
        "training_args_vit = TrainingArguments(\n",
        "    output_dir=\"./vit_cifar10_results_v2\", # Farklı bir çıktı dizini\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    logging_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    save_total_limit=2,\n",
        "    report_to=\"tensorboard\",\n",
        "    remove_unused_columns=False, # <<-- ÖNEMLİ DÜZELTME: Transform fonksiyonunun 'img' sütununa erişebilmesi için.\n",
        "    # fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "print(f\"\\nEğitim argümanları (ViT için - remove_unused_columns=False ile) tanımlandı. Çıktı dizini: {training_args_vit.output_dir}\")\n",
        "\n",
        "# 3. Trainer Objesinin Oluşturulması\n",
        "if 'model_vit' in globals() and model_vit is not None and \\\n",
        "   'processed_dataset_cifar' in globals() and processed_dataset_cifar is not None and \\\n",
        "   'image_processor' in globals() and image_processor is not None:\n",
        "\n",
        "    global trainer_vit # trainer_vit'i global yapalım\n",
        "    trainer_vit = Trainer(\n",
        "        model=model_vit,\n",
        "        args=training_args_vit,\n",
        "        train_dataset=processed_dataset_cifar[\"train\"],\n",
        "        eval_dataset=processed_dataset_cifar[\"validation\"],\n",
        "        tokenizer=image_processor, # ViT için tokenizer yerine image_processor\n",
        "        compute_metrics=compute_metrics_image_clf,\n",
        "        data_collator=default_data_collator,\n",
        "    )\n",
        "    print(\"\\nTrainer objesi (ViT için) başarıyla oluşturuldu.\")\n",
        "\n",
        "    print(\"\\nViT modeli eğitimi başlatılıyor...\")\n",
        "    print(f\"Kullanılan cihaz: {device}. Epoch: {training_args_vit.num_train_epochs}, Train Batch: {training_args_vit.per_device_train_batch_size}\")\n",
        "\n",
        "    global training_time_vit # training_time_vit'i global yapalım\n",
        "    start_time_vit_train = time.time()\n",
        "    try:\n",
        "        train_result_vit = trainer_vit.train()\n",
        "        end_time_vit_train = time.time()\n",
        "        training_time_vit = end_time_vit_train - start_time_vit_train\n",
        "\n",
        "        print(f\"\\nEğitim tamamlandı! Toplam eğitim süresi: {training_time_vit:.2f} saniye ({training_time_vit/60:.2f} dakika).\")\n",
        "\n",
        "        if hasattr(train_result_vit, 'metrics') and train_result_vit.metrics:\n",
        "            print(\"Genel eğitim sonuç metrikleri (trainer.train() dönüşünden):\")\n",
        "            for key, value in train_result_vit.metrics.items():\n",
        "                print(f\"  {key}: {value}\")\n",
        "\n",
        "        best_model_path_vit = f\"{training_args_vit.output_dir}/best_model\"\n",
        "        trainer_vit.save_model(best_model_path_vit)\n",
        "        image_processor.save_pretrained(best_model_path_vit)\n",
        "        print(f\"Eğitim sonrası (en iyi) ViT modeli ve image processor '{best_model_path_vit}' adresine kaydedildi.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nViT modeli eğitimi sırasında bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        if 'train_result_vit' not in globals(): train_result_vit = None\n",
        "        training_time_vit = None\n",
        "else:\n",
        "    print(\"\\nModel, işlenmiş veri seti veya image processor bulunamadığı için Trainer oluşturulamadı ve eğitim başlatılamadı.\")\n",
        "    if 'trainer_vit' in globals(): del trainer_vit\n",
        "    if 'train_result_vit' not in globals(): train_result_vit = None\n",
        "    training_time_vit = None"
      ],
      "metadata": {
        "id": "ZAubZXv2EU6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 7 (ViT): Eğitilmiş Modelin Test Seti Üzerinde Değerlendirilmesi\n",
        "\n",
        "* **Amaç:**\n",
        "    Hücre 6'da eğitimi tamamlanan ve en iyi checkpoint'i yüklenmiş olan Vision Transformer (ViT) modelinin, daha önce hiç görmediği CIFAR-10 test veri seti üzerindeki nihai sınıflandırma performansını ölçmek. Proje isterlerinde belirtilen tüm metrikleri (Accuracy, Precision Macro, Recall Macro, F1 Macro, Specificity Macro, AUC Macro) hesaplamak.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  Bir önceki hücrede eğitimi tamamlanmış ve en iyi modeli yüklemiş olan `trainer_vit` objesi kullanılır.\n",
        "    2.  `trainer_vit.evaluate(eval_dataset=processed_dataset_cifar[\"test\"])` metodu çağrılır. Bu metod:\n",
        "        * Belirtilen `eval_dataset` (test setimiz) üzerinde modelin tahminlerini yapar.\n",
        "        * Hücre 6'da tanımlanan `compute_metrics_image_clf` fonksiyonunu kullanarak tüm performans metriklerini hesaplar.\n",
        "        * Hesaplanan metrikleri içeren bir sözlük (`vit_test_metrics`) döndürür.\n",
        "    3.  Döndürülen metrikler ekrana okunaklı bir formatta yazdırılır.\n",
        "    4.  Bu metrikler, daha sonraki analizler veya raporlama için `vit_test_metrics` adlı bir global değişkende saklanır.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar (Beklenen):**\n",
        "    * Test seti üzerinde değerlendirme yapılırken bir ilerleme çubuğu görülebilir.\n",
        "    * Çıktıda, test seti için hesaplanan kayıp (Loss) ve diğer tüm performans metrikleri (Accuracy, Precision Macro, Recall Macro, F1 Macro, Specificity Macro, AUC Macro) listelenir.\n",
        "    * Bu metrikler, modelin CIFAR-10 test verisi üzerindeki genelleme yeteneği hakkında nihai bir değerlendirme sunar."
      ],
      "metadata": {
        "id": "jYWofRobGbeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 7 (ViT): Eğitilmiş Modelin Test Seti Üzerinde Değerlendirilmesi\n",
        "\n",
        "# Gerekli değişkenlerin (trainer_vit, processed_dataset_cifar)\n",
        "# önceki hücrelerde doğru şekilde tanımlandığını varsayıyoruz.\n",
        "if 'trainer_vit' in globals() and trainer_vit is not None and \\\n",
        "   'processed_dataset_cifar' in globals() and \"test\" in processed_dataset_cifar:\n",
        "\n",
        "    print(\"Eğitilmiş ViT modeli test seti üzerinde değerlendiriliyor...\")\n",
        "    try:\n",
        "        # trainer_vit.model zaten en iyi modeli içermeli (load_best_model_at_end=True sayesinde)\n",
        "        test_metrics_vit_output = trainer_vit.evaluate(eval_dataset=processed_dataset_cifar[\"test\"])\n",
        "\n",
        "        print(\"\\nViT Test Seti Performans Metrikleri:\")\n",
        "        # Trainer evaluate metodu, metrik isimlerinin başına 'eval_' ekler.\n",
        "        print(f\"  Test Kaybı (Loss): {test_metrics_vit_output.get('eval_loss', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Accuracy: {test_metrics_vit_output.get('eval_accuracy', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Precision (Macro): {test_metrics_vit_output.get('eval_precision_macro', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Recall (Macro): {test_metrics_vit_output.get('eval_recall_macro', 'N/A'):.4f}\")\n",
        "        print(f\"  Test F1-Score (Macro): {test_metrics_vit_output.get('eval_f1_macro', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Specificity (Macro): {test_metrics_vit_output.get('eval_specificity_macro', 'N/A'):.4f}\")\n",
        "        print(f\"  Test AUC (Macro): {test_metrics_vit_output.get('eval_auc_macro', 'N/A'):.4f}\")\n",
        "\n",
        "        # Metrikleri globalde saklayalım\n",
        "        global vit_test_metrics\n",
        "        vit_test_metrics = test_metrics_vit_output\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nViT Test seti değerlendirmesi sırasında bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        if 'vit_test_metrics' not in globals(): vit_test_metrics = None\n",
        "else:\n",
        "    print(\"Hata: 'trainer_vit' objesi veya 'processed_dataset_cifar['test']' bulunamadı.\")\n",
        "    print(\"Lütfen önceki hücrelerin (özellikle Hücre 6 - ViT eğitimi) doğru çalıştığından emin olun.\")\n",
        "    if 'vit_test_metrics' not in globals(): vit_test_metrics = None"
      ],
      "metadata": {
        "id": "pbv6jmtEGemp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 8 (ViT): Test Seti Sonuçlarının Görselleştirilmesi ve Eğitim Grafikleri\n",
        "\n",
        "* **Amaç:**\n",
        "    ViT modelinin test seti üzerindeki sınıflandırma performansını Karmaşıklık Matrisi ve ROC Eğrisi ile görsel olarak analiz etmek. Ayrıca, modelin eğitim süreci boyunca performansının nasıl değiştiğini (kayıp ve anahtar metrikler açısından) hem eğitim hem de doğrulama veri setleri üzerinde epoch bazında görselleştirmek.\n",
        "\n",
        "* **Yapılan İşlemler (Görselleştirmeler):**\n",
        "    1.  `trainer_vit.predict(processed_dataset_cifar[\"test\"])` ile test seti üzerindeki ham tahminler (logitler) ve gerçek etiketler alınır.\n",
        "    2.  Logitler olasılıklara dönüştürülür ve tahmin edilen etiketler belirlenir.\n",
        "    3.  **Karmaşıklık Matrisi:** `sklearn.metrics.confusion_matrix` ile 10x10'luk karmaşıklık matrisi hesaplanır ve `seaborn.heatmap` ile görselleştirilir. `label_feature_cifar` kullanılarak eksen etiketleri sınıf isimleriyle (örn: \"airplane\", \"cat\") ayarlanır.\n",
        "    4.  **ROC Eğrisi ve AUC (Çok Sınıflı Durum İçin):**\n",
        "        * Her bir sınıf için One-vs-Rest (OvR) yaklaşımıyla ROC eğrileri çizdirilir veya daha genel bir bakış için makro-ortalama ROC eğrisi çizdirilir.\n",
        "        * Test seti için `compute_metrics_image_clf` fonksiyonu zaten `auc_macro` değerini hesaplamıştır. Bu değer teyit edilir ve makro-ortalama ROC eğrisi grafiğine eklenir.\n",
        "* **Yapılan İşlemler (Eğitim/Doğrulama Grafikleri):**\n",
        "    1.  Hücre 6'daki eğitim sırasında `Trainer` tarafından kaydedilen `trainer_vit.state.log_history` alınır.\n",
        "    2.  Bu loglar bir `pandas.DataFrame`'e dönüştürülür.\n",
        "    3.  Eğitim logları ve doğrulama logları ayrılarak:\n",
        "        * \"Epoch Bazında Eğitim ve Doğrulama Kaybı\" grafiği çizdirilir.\n",
        "        * \"Epoch Bazında Doğrulama Metrikleri (Accuracy & F1 Macro)\" grafiği (veya ayrı ayrı) çizdirilir.\n",
        "    4.  Grafiklerin başlıkları, eksen etiketleri ve lejantları eklenir.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar (Beklenen):**\n",
        "    * Test seti için 10x10 boyutunda bir Karmaşıklık Matrisi grafiği çizilir.\n",
        "    * Makro-Ortalama ROC Eğrisi grafiği çizilir ve AUC değeri (Hücre 7'de hesaplananla tutarlı olmalı) gösterilir.\n",
        "    * Eğitim ve doğrulama kayıplarının epoch'lar boyunca değişimini gösteren bir grafik elde edilir. Bu, aşırı öğrenme olup olmadığını ve modelin nasıl öğrendiğini gösterir.\n",
        "    * Doğrulama doğruluğu ve F1 makro skorunun epoch'lar boyunca değişimini gösteren bir grafik elde edilir."
      ],
      "metadata": {
        "id": "MPBLDxICGjqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 8 (ViT): Test Seti Sonuçlarının Görselleştirilmesi ve Eğitim Grafikleri\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, RocCurveDisplay\n",
        "from sklearn.metrics import auc as sklearn_auc\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# --- Test Seti Görselleştirmeleri ---\n",
        "# Gerekli değişkenlerin (trainer_vit, processed_dataset_cifar, vit_test_metrics, label_feature_cifar)\n",
        "# önceki hücrelerden doğru geldiğini varsayıyoruz.\n",
        "if 'trainer_vit' in globals() and trainer_vit is not None and \\\n",
        "   'processed_dataset_cifar' in globals() and \"test\" in processed_dataset_cifar and \\\n",
        "   'vit_test_metrics' in globals() and vit_test_metrics is not None and \\\n",
        "   'label_feature_cifar' in globals() and label_feature_cifar is not None and hasattr(label_feature_cifar, 'names'):\n",
        "\n",
        "    print(\"ViT Test seti üzerinde tahminler (logitler ve olasılıklar) alınıyor...\")\n",
        "    try:\n",
        "        test_predictions_output_vit = trainer_vit.predict(processed_dataset_cifar[\"test\"])\n",
        "\n",
        "        logits_vit = test_predictions_output_vit.predictions\n",
        "        probabilities_vit = torch.softmax(torch.tensor(logits_vit), dim=-1).cpu().numpy()\n",
        "        predicted_labels_vit = np.argmax(logits_vit, axis=1)\n",
        "        true_labels_vit = test_predictions_output_vit.label_ids\n",
        "\n",
        "        num_classes_vit = label_feature_cifar.num_classes\n",
        "        class_names_vit = label_feature_cifar.names\n",
        "\n",
        "        # 1. Karmaşıklık Matrisi\n",
        "        cm_vit = confusion_matrix(true_labels_vit, predicted_labels_vit, labels=list(range(num_classes_vit)))\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm_vit, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                    xticklabels=class_names_vit,\n",
        "                    yticklabels=class_names_vit)\n",
        "        plt.title('Karmaşıklık Matrisi (ViT - CIFAR-10 Test Seti)')\n",
        "        plt.xlabel('Tahmin Edilen Etiket')\n",
        "        plt.ylabel('Gerçek Etiket')\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # 2. ROC Eğrisi ve AUC (Çok Sınıflı Durum - Macro Average)\n",
        "        y_true_binarized_vit = label_binarize(true_labels_vit, classes=list(range(num_classes_vit)))\n",
        "\n",
        "        fpr_vit = dict()\n",
        "        tpr_vit = dict()\n",
        "        roc_auc_vit = dict()\n",
        "\n",
        "        for i in range(num_classes_vit):\n",
        "            if y_true_binarized_vit.shape[1] > i : # Eğer binarize edilmiş etiketlerde o sınıf varsa\n",
        "                fpr_vit[i], tpr_vit[i], _ = roc_curve(y_true_binarized_vit[:, i], probabilities_vit[:, i])\n",
        "                roc_auc_vit[i] = sklearn_auc(fpr_vit[i], tpr_vit[i])\n",
        "            else: # Nadir durum, eğer bir sınıf hiç yoksa veya binarizasyonda sorun olduysa\n",
        "                fpr_vit[i], tpr_vit[i], roc_auc_vit[i] = np.array([0]), np.array([0]), 0.0\n",
        "\n",
        "\n",
        "        all_fpr_vit = np.unique(np.concatenate([fpr_vit[i] for i in range(num_classes_vit) if i in fpr_vit]))\n",
        "        mean_tpr_vit = np.zeros_like(all_fpr_vit)\n",
        "        for i in range(num_classes_vit):\n",
        "            if i in fpr_vit and i in tpr_vit: # Sadece geçerli olanları interpolasyon yap\n",
        "                 mean_tpr_vit += np.interp(all_fpr_vit, fpr_vit[i], tpr_vit[i])\n",
        "        mean_tpr_vit /= num_classes_vit # Sınıf sayısına böl\n",
        "        roc_auc_macro_manual_vit = sklearn_auc(all_fpr_vit, mean_tpr_vit)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.plot(all_fpr_vit, mean_tpr_vit,\n",
        "                 label=f'Makro-Ortalama ROC eğrisi (AUC = {roc_auc_macro_manual_vit:.4f})',\n",
        "                 color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('Yanlış Pozitif Oranı (False Positive Rate)')\n",
        "        plt.ylabel('Doğru Pozitif Oranı (True Positive Rate)')\n",
        "        plt.title('ViT: Çok Sınıflı ROC Eğrisi (Makro Ortalama) - CIFAR-10 Test')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\nHücre 7'de hesaplanan Test AUC (Macro) (trainer.evaluate): {vit_test_metrics.get('eval_auc_macro', 'N/A'):.4f}\")\n",
        "        print(f\"Bu hücrede Makro-Ortalama ROC için hesaplanan AUC (sklearn): {roc_auc_macro_manual_vit:.4f}\")\n",
        "\n",
        "    except Exception as e_viz:\n",
        "        print(f\"\\nViT Test seti görselleştirmeleri oluşturulurken bir hata oluştu: {e_viz}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "else:\n",
        "    print(\"Hata: ViT Test görselleştirmeleri için gerekli değişkenler bulunamadı.\")\n",
        "\n",
        "# --- Eğitim ve Doğrulama Log Grafikleri ---\n",
        "if 'trainer_vit' in globals() and trainer_vit is not None and \\\n",
        "   hasattr(trainer_vit.state, 'log_history') and trainer_vit.state.log_history:\n",
        "\n",
        "    log_history_vit = trainer_vit.state.log_history\n",
        "    print(\"\\nViT Eğitim Logları İşleniyor...\")\n",
        "    log_df_vit = pd.DataFrame(log_history_vit)\n",
        "\n",
        "    train_logs_df_vit = log_df_vit[log_df_vit['loss'].notna() & log_df_vit['eval_loss'].isna()].copy()\n",
        "    eval_logs_df_vit = log_df_vit[log_df_vit['eval_loss'].notna()].copy()\n",
        "\n",
        "    if not train_logs_df_vit.empty and not eval_logs_df_vit.empty:\n",
        "        # Kayıp Grafiği\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(train_logs_df_vit['epoch'], train_logs_df_vit['loss'], 'b-o', label='Eğitim Kaybı')\n",
        "        plt.plot(eval_logs_df_vit['epoch'], eval_logs_df_vit['eval_loss'], 'r-s', label='Doğrulama Kaybı')\n",
        "        plt.title('ViT: Epoch Bazında Eğitim ve Doğrulama Kaybı')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Kayıp (Loss)')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        epochs_present_vit = sorted(list(set(eval_logs_df_vit['epoch'].round().tolist())))\n",
        "        if epochs_present_vit:\n",
        "            min_e_vit, max_e_vit = min(epochs_present_vit), max(epochs_present_vit)\n",
        "            plt.xticks(np.arange(int(min_e_vit), int(max_e_vit) + 1, 1.0)) # Epochları tam sayı olarak göster\n",
        "            plt.xlim(left=int(min_e_vit) - 0.5 if int(min_e_vit) > 0 else 0, right=int(max_e_vit) + 0.5)\n",
        "        plt.show()\n",
        "\n",
        "        # Doğruluk ve F1 Macro Grafiği\n",
        "        fig, ax1_vit = plt.subplots(figsize=(12, 6))\n",
        "        color = 'tab:green'\n",
        "        ax1_vit.set_xlabel('Epoch')\n",
        "        ax1_vit.set_ylabel('Doğruluk (Accuracy)', color=color)\n",
        "        ax1_vit.plot(eval_logs_df_vit['epoch'], eval_logs_df_vit['eval_accuracy'], color=color, marker='^', linestyle='-', label='Doğrulama Doğruluğu')\n",
        "        ax1_vit.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "        ax2_vit = ax1_vit.twinx()\n",
        "        color = 'tab:purple'\n",
        "        ax2_vit.set_ylabel('F1 Skoru (Macro)', color=color)\n",
        "        ax2_vit.plot(eval_logs_df_vit['epoch'], eval_logs_df_vit['eval_f1_macro'], color=color, marker='x', linestyle='--', label='Doğrulama F1 (Macro)')\n",
        "        ax2_vit.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "        plt.title('ViT: Epoch Bazında Doğrulama Metrikleri')\n",
        "        fig.tight_layout()\n",
        "        lines, labels_ax1 = ax1_vit.get_legend_handles_labels()\n",
        "        lines2, labels_ax2 = ax2_vit.get_legend_handles_labels()\n",
        "        ax2_vit.legend(lines + lines2, labels_ax1 + labels_ax2, loc='best')\n",
        "        if epochs_present_vit:\n",
        "            plt.xticks(np.arange(int(min_e_vit), int(max_e_vit) + 1, 1.0))\n",
        "            ax1_vit.set_xlim(left=int(min_e_vit) - 0.5 if int(min_e_vit) > 0 else 0, right=int(max_e_vit) + 0.5)\n",
        "        plt.grid(True, axis='x')\n",
        "        ax1_vit.grid(True, axis='y', linestyle=':', alpha=0.7)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"ViT Grafiklerini çizdirmek için yeterli eğitim veya doğrulama logu bulunamadı.\")\n",
        "else:\n",
        "    print(\"Hata: ViT Log Grafikleri için 'trainer_vit' objesi veya 'log_history' bulunamadı.\")"
      ],
      "metadata": {
        "id": "wZwK9IZeGilR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 9 (ViT): Eğitim ve Çıkarım Sürelerinin Hesaplanması\n",
        "\n",
        "* **Amaç:**\n",
        "    Vision Transformer (ViT) modelinin hem eğitim (fine-tuning) süresini hem de eğitilmiş modelle yeni görüntüler üzerinde tahmin yapma (çıkarım/inference) hızını belirlemek.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  **Eğitim Süresi:** Hücre 6'da model eğitimi sırasında ölçülen ve `training_time_vit` değişkeninde saklanan toplam eğitim süresi saniye ve dakika cinsinden yazdırılır.\n",
        "    2.  **Örnek Başına Ortalama Çıkarım Süresi:**\n",
        "        * `trainer_vit.model` (en iyi checkpoint yüklendiği varsayılır) değerlendirme moduna (`model_vit.eval()`) alınır.\n",
        "        * Ön işlenmiş (dönüşümleri atanmış) test seti (`processed_dataset_cifar[\"test\"]`) kullanılır.\n",
        "        * `torch.utils.data.DataLoader` ile test verileri yığınlar (batch) halinde hazırlanır. `default_data_collator` kullanılır.\n",
        "        * `torch.no_grad()` bloğu içinde, her bir yığın için modelden tahminler (`pixel_values` ile) alınır ve yığının işlenme süresi ölçülür.\n",
        "        * Toplam çıkarım süresi ve işlenen toplam görüntü sayısı kullanılarak görüntü başına ortalama çıkarım süresi ve saniyede işlenen görüntü sayısı hesaplanıp yazdırılır.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar (Beklenen):**\n",
        "    * Toplam eğitim süresi yazdırılır.\n",
        "    * Test seti üzerinde çıkarım yapılırken ilerleme çubuğu gösterilir.\n",
        "    * Çıkarım tamamlandığında, toplam çıkarım süresi, görüntü başına ortalama çıkarım süresi ve saniyede işlenen görüntü sayısı ekrana yazdırılır."
      ],
      "metadata": {
        "id": "im9EmpO8Gsvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 9 (ViT): Eğitim ve Çıkarım Sürelerinin Hesaplanması\n",
        "\n",
        "# time, torch, tqdm.auto, DataLoader zaten import edilmiş olmalı.\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import default_data_collator # Trainer'ın kullandığı collator\n",
        "\n",
        "# 1. Eğitim Süresi\n",
        "if 'training_time_vit' in globals() and training_time_vit is not None:\n",
        "    print(f\"Toplam ViT Model Eğitim Süresi: {training_time_vit:.2f} saniye ({training_time_vit/60:.2f} dakika)\")\n",
        "else:\n",
        "    # Eğer training_time_vit tanımlanmadıysa, trainer_vit.state.log_history'den almayı deneyelim\n",
        "    if 'trainer_vit' in globals() and hasattr(trainer_vit.state, 'log_history') and trainer_vit.state.log_history:\n",
        "        train_log_final_entry = next((item for item in reversed(trainer_vit.state.log_history) if \"train_runtime\" in item), None)\n",
        "        if train_log_final_entry:\n",
        "            calculated_training_time_vit = train_log_final_entry['train_runtime']\n",
        "            print(f\"Toplam ViT Model Eğitim Süresi (logdan alındı): {calculated_training_time_vit:.2f} saniye ({calculated_training_time_vit/60:.2f} dakika)\")\n",
        "            training_time_vit = calculated_training_time_vit # Değişkeni güncelleyelim\n",
        "        else:\n",
        "            print(\"ViT eğitim süresi bilgisi `training_time_vit` değişkeninden veya `log_history`'den alınamadı.\")\n",
        "    else:\n",
        "        print(\"ViT eğitim süresi bilgisi `training_time_vit` değişkeninden veya `log_history`'den alınamadı.\")\n",
        "\n",
        "\n",
        "# 2. Örnek Başına Ortalama Çıkarım Süresi (Test Seti Üzerinden)\n",
        "avg_inference_time_per_image_vit = None\n",
        "# Gerekli değişkenlerin varlığını kontrol edelim\n",
        "if 'model_vit' in globals() and model_vit is not None and \\\n",
        "   'processed_dataset_cifar' in globals() and \"test\" in processed_dataset_cifar and \\\n",
        "   'device' in globals() :\n",
        "\n",
        "    model_vit.eval()\n",
        "\n",
        "    # processed_dataset_cifar[\"test\"] zaten .with_transform(preprocess_eval) ile ayarlanmıştı.\n",
        "    # Bu transform, 'pixel_values' ve 'labels' içeren dict'ler döndürür.\n",
        "    # DataLoader için data_collator kullanalım.\n",
        "    inference_batch_size_vit = training_args_vit.per_device_eval_batch_size if 'training_args_vit' in globals() else 64\n",
        "\n",
        "    # DataLoader'a doğrudan dönüştürülmüş veri setini verelim\n",
        "    # Not: processed_dataset_cifar[\"test\"] içindeki örnekler zaten tensör formatında olmalı\n",
        "    # çünkü preprocess_eval 'pixel_values' ve 'labels' tensörleri döndürüyor.\n",
        "    # Eğer DataLoader hata verirse, .with_transform(None) ile ham veriyi alıp kendimiz collate edebiliriz.\n",
        "    # Ancak default_data_collator genellikle işe yarar.\n",
        "\n",
        "    # Test için kullanılacak dataset (transform uygulanmış haliyle)\n",
        "    eval_ds_for_inference = processed_dataset_cifar[\"test\"]\n",
        "\n",
        "    # Trainer'ın kullandığı gibi bir DataLoader oluşturalım\n",
        "    # default_data_collator, list of dicts (her biri 'pixel_values', 'labels' içerir) alıp\n",
        "    # bunları bir batch dict'ine ({'pixel_values': batched_pixels, 'labels': batched_labels}) dönüştürür.\n",
        "    inference_dataloader_vit = DataLoader(\n",
        "        eval_ds_for_inference,\n",
        "        batch_size=inference_batch_size_vit,\n",
        "        collate_fn=default_data_collator\n",
        "    )\n",
        "\n",
        "    total_inference_time_val_vit = 0.0\n",
        "    num_images_processed = 0\n",
        "\n",
        "    print(f\"\\nViT Test seti üzerinde çıkarım süresi hesaplanıyor (Batch Size: {inference_batch_size_vit})...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(inference_dataloader_vit, desc=\"ViT Çıkarım\"):\n",
        "            # default_data_collator 'labels'ı da getirecektir, çıkarım için gerekmese de sorun değil.\n",
        "            # Sadece 'pixel_values'ı modele verelim.\n",
        "            pixel_values = batch.get('pixel_values').to(device)\n",
        "\n",
        "            if pixel_values is None:\n",
        "                print(\"Uyarı: Batch'te 'pixel_values' bulunamadı, bu yığın atlanıyor.\")\n",
        "                num_images_processed += batch.get('labels').size(0) if 'labels' in batch else inference_batch_size_vit\n",
        "                continue\n",
        "\n",
        "            start_batch_time = time.perf_counter()\n",
        "            outputs = model_vit(pixel_values=pixel_values) # Sadece pixel_values ile çağır\n",
        "            end_batch_time = time.perf_counter()\n",
        "\n",
        "            batch_time = end_batch_time - start_batch_time\n",
        "            total_inference_time_val_vit += batch_time\n",
        "            num_images_processed += pixel_values.size(0)\n",
        "\n",
        "    if num_images_processed > 0 and total_inference_time_val_vit > 0 :\n",
        "        avg_inference_time_per_image_vit = total_inference_time_val_vit / num_images_processed\n",
        "        images_per_second_inference_vit = num_images_processed / total_inference_time_val_vit\n",
        "        print(f\"\\nToplam {num_images_processed} görüntü için ViT çıkarım süresi: {total_inference_time_val_vit:.4f} saniye\")\n",
        "        print(f\"Görüntü başına ortalama ViT çıkarım süresi: {avg_inference_time_per_image_vit:.6f} saniye/görüntü\")\n",
        "        print(f\"Saniyede işlenen ViT görüntü sayısı (çıkarım): {images_per_second_inference_vit:.2f} görüntü/saniye\")\n",
        "    elif num_images_processed > 0 and total_inference_time_val_vit == 0 :\n",
        "        print(f\"\\nToplam {num_images_processed} görüntü için ViT çıkarım süresi çok kısa, hız çok yüksek.\")\n",
        "        avg_inference_time_per_image_vit = 0.0\n",
        "    else:\n",
        "        print(\"ViT Çıkarım için hiç görüntü işlenemedi veya süre ölçülemedi.\")\n",
        "\n",
        "else:\n",
        "    print(\"Hata: ViT Modeli, işlenmiş test seti veya cihaz bilgisi bulunamadı.\")"
      ],
      "metadata": {
        "id": "woI2-mayGuLp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}